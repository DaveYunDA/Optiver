{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "def vol(stock, second_interval):\n",
    "    log_r1 = []\n",
    "    time_IDs = np.unique(stock.iloc[:, 0])\n",
    "    print(time_IDs)\n",
    "\n",
    "    #Generate Weighted Average Price\n",
    "    stock[\"WAP\"] = (stock[\"bid_price1\"] * stock[\"ask_size1\"] + stock[\"ask_price1\"] * stock[\"bid_size1\"]) / (stock[\"bid_size1\"] + stock[\"ask_size1\"])\n",
    "\n",
    "    for i in range(len(time_IDs)):\n",
    "        sec = stock.loc[stock.iloc[:, 0] == time_IDs[i], 'seconds_in_bucket'].values\n",
    "        price = stock.loc[stock.iloc[:, 0] == time_IDs[i], 'WAP'].values\n",
    "        log_r = np.log(price[1:] / price[0:(len(price) - 1)])\n",
    "        log_r1.append(pd.DataFrame({'time': sec[1:], 'log_return': log_r}))\n",
    "        time_no_change = np.setdiff1d(np.arange(1, 601), log_r1[i]['time'].values)\n",
    "        if len(time_no_change) > 0:\n",
    "            new_df = pd.DataFrame({'time': time_no_change, 'log_return': 0})\n",
    "            log_r1[i] = pd.concat([log_r1[i], new_df])\n",
    "            log_r1[i] = log_r1[i].sort_values(by='time')\n",
    "\n",
    "    vol = []\n",
    "    def comp_vol(x):\n",
    "        return np.sqrt(np.sum(x ** 2))\n",
    "\n",
    "    for i in range(len(log_r1)):\n",
    "        log_r1[i]['time_bucket'] = np.ceil(log_r1[i]['time'] / second_interval)\n",
    "        vol.append(log_r1[i].groupby('time_bucket')['log_return'].agg(comp_vol).reset_index())\n",
    "        vol[i].columns = ['time_bucket', 'volatility']\n",
    "    out = []\n",
    "    times = []\n",
    "    for i in range(len(vol)):\n",
    "        for j in range(int(600/second_interval)):\n",
    "            out.append(vol[i][\"volatility\"][j])\n",
    "            times.append(int(vol[i][\"time_bucket\"][j]))\n",
    "    vol = np.array(out)\n",
    "\n",
    "    return vol, times\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRYING TO FIND OPTIMAL ALPHA VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.1  0.11 0.12 0.13 0.14\n",
      " 0.15 0.16 0.17 0.18 0.19 0.2  0.21 0.22 0.23 0.24 0.25 0.26 0.27 0.28\n",
      " 0.29 0.3  0.31 0.32 0.33 0.34 0.35 0.36 0.37 0.38 0.39 0.4  0.41 0.42\n",
      " 0.43 0.44 0.45 0.46 0.47 0.48 0.49 0.5  0.51 0.52 0.53 0.54 0.55 0.56\n",
      " 0.57 0.58 0.59 0.6  0.61 0.62 0.63 0.64 0.65 0.66 0.67 0.68 0.69 0.7\n",
      " 0.71 0.72 0.73 0.74 0.75 0.76 0.77 0.78 0.79 0.8  0.81 0.82 0.83 0.84\n",
      " 0.85 0.86 0.87 0.88 0.89 0.9  0.91 0.92 0.93 0.94 0.95 0.96 0.97 0.98\n",
      " 0.99]\n"
     ]
    },
    {
     "ename": "DataError",
     "evalue": "No numeric types to aggregate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\window\\rolling.py:404\u001b[0m, in \u001b[0;36mBaseWindow._prep_values\u001b[1;34m(self, values)\u001b[0m\n\u001b[0;32m    403\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 404\u001b[0m         values \u001b[39m=\u001b[39m ensure_float64(values)\n\u001b[0;32m    405\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mpandas\\_libs\\algos_common_helper.pxi:42\u001b[0m, in \u001b[0;36mpandas._libs.algos.ensure_float64\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\window\\rolling.py:483\u001b[0m, in \u001b[0;36mBaseWindow._apply_series\u001b[1;34m(self, homogeneous_func, name)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 483\u001b[0m     values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prep_values(obj\u001b[39m.\u001b[39;49m_values)\n\u001b[0;32m    484\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mNotImplementedError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\window\\rolling.py:406\u001b[0m, in \u001b[0;36mBaseWindow._prep_values\u001b[1;34m(self, values)\u001b[0m\n\u001b[0;32m    405\u001b[0m     \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m--> 406\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcannot handle this type -> \u001b[39m\u001b[39m{\u001b[39;00mvalues\u001b[39m.\u001b[39mdtype\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m    408\u001b[0m \u001b[39m# Convert inf to nan for C funcs\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot handle this type -> object",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mDataError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39m# Loop through alpha values\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39mfor\u001b[39;00m alpha \u001b[39min\u001b[39;00m alphas:\n\u001b[0;32m     18\u001b[0m     \u001b[39m# Calculate the EWMA of the training set using pandas\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m     ewma_train_volatility \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame\u001b[39m.\u001b[39;49mewm(pd\u001b[39m.\u001b[39;49mSeries(train_volatility),alpha\u001b[39m=\u001b[39;49malpha)\u001b[39m.\u001b[39;49mmean()\n\u001b[0;32m     20\u001b[0m     \u001b[39m# Initialize list for predicted volatilities\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     predicted_volatility \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\window\\ewm.py:581\u001b[0m, in \u001b[0;36mExponentialMovingWindow.mean\u001b[1;34m(self, numeric_only, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    572\u001b[0m     deltas \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_deltas\n\u001b[0;32m    573\u001b[0m     window_func \u001b[39m=\u001b[39m partial(\n\u001b[0;32m    574\u001b[0m         window_aggregations\u001b[39m.\u001b[39mewm,\n\u001b[0;32m    575\u001b[0m         com\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_com,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         normalize\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(window_func, name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmean\u001b[39;49m\u001b[39m\"\u001b[39;49m, numeric_only\u001b[39m=\u001b[39;49mnumeric_only)\n\u001b[0;32m    582\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    583\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mengine must be either \u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumba\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mcython\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\window\\rolling.py:663\u001b[0m, in \u001b[0;36mBaseWindow._apply\u001b[1;34m(self, func, name, numeric_only, numba_args, **kwargs)\u001b[0m\n\u001b[0;32m    660\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m    662\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmethod \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msingle\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 663\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply_blockwise(homogeneous_func, name, numeric_only)\n\u001b[0;32m    664\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    665\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_tablewise(homogeneous_func, name, numeric_only)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\window\\rolling.py:503\u001b[0m, in \u001b[0;36mBaseWindow._apply_blockwise\u001b[1;34m(self, homogeneous_func, name, numeric_only)\u001b[0m\n\u001b[0;32m    501\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_numeric_only(name, numeric_only)\n\u001b[0;32m    502\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_selected_obj\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 503\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply_series(homogeneous_func, name)\n\u001b[0;32m    505\u001b[0m obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_data(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_selected_obj, numeric_only)\n\u001b[0;32m    506\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcount\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    507\u001b[0m     \u001b[39m# GH 12541: Special case for count where we support date-like types\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\window\\rolling.py:485\u001b[0m, in \u001b[0;36mBaseWindow._apply_series\u001b[1;34m(self, homogeneous_func, name)\u001b[0m\n\u001b[0;32m    483\u001b[0m     values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prep_values(obj\u001b[39m.\u001b[39m_values)\n\u001b[0;32m    484\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mNotImplementedError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m--> 485\u001b[0m     \u001b[39mraise\u001b[39;00m DataError(\u001b[39m\"\u001b[39m\u001b[39mNo numeric types to aggregate\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m    487\u001b[0m result \u001b[39m=\u001b[39m homogeneous_func(values)\n\u001b[0;32m    488\u001b[0m index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slice_axis_for_step(obj\u001b[39m.\u001b[39mindex, result)\n",
      "\u001b[1;31mDataError\u001b[0m: No numeric types to aggregate"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_volatility, test_volatility = train_test_split(volatility, test_size=0.2)\n",
    "\n",
    "\n",
    "# Set the range of alpha values to test\n",
    "alphas = np.arange(0.01, 1, 0.01)\n",
    "print(alphas)\n",
    "\n",
    "# Initialize variables to store the best alpha and corresponding performance metric\n",
    "best_alpha = 0\n",
    "best_mse = float('inf')\n",
    "\n",
    "# Loop through alpha values\n",
    "for alpha in alphas:\n",
    "    # Calculate the EWMA of the training set using pandas\n",
    "    ewma_train_volatility = pd.DataFrame.ewm(pd.Series(train_volatility),alpha=alpha).mean()\n",
    "    # Initialize list for predicted volatilities\n",
    "    predicted_volatility = []\n",
    "    # Loop through the test set\n",
    "    for i in range(len(test_volatility)):\n",
    "        # Add current test point to training data\n",
    "        train_volatility = np.append(train_volatility, test_volatility[i])\n",
    "        # Update EWMA with new point\n",
    "        ewma_train_volatility = pd.DataFrame.ewm(pd.Series(train_volatility), alpha=alpha).mean()\n",
    "        # Get the last value of the EWMA as the forecasted volatility\n",
    "        forecasted_volatility = ewma_train_volatility.values[-1]\n",
    "        # Append forecasted value to list of predicted volatilities\n",
    "        predicted_volatility.append(forecasted_volatility)\n",
    "    # Calculate mean squared error between predicted and actual volatilities\n",
    "    mse = mean_squared_error(test_volatility, predicted_volatility)\n",
    "    # Update best alpha and corresponding performance metric if applicable\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_alpha = alpha\n",
    "\n",
    "# Print the optimal alpha and corresponding performance metric\n",
    "print(f\"Optimal alpha: {best_alpha}\")\n",
    "print(f\"Best MSE: {best_mse}\")\n",
    "\n",
    "\n",
    "# Print optimal alpha value\n",
    "print('Optimal alpha value:', alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ewma_mse(volatility, span):\n",
    "    # Split the data into training and testing sets\n",
    "    #train_volatility, test_volatility = train_test_split(volatility, test_size=0.2, random_state= 1)\n",
    "    train_volatility = volatility[:round(len(volatility)*0.8)]\n",
    "    test_volatility = volatility[round(len(volatility)*0.8):]\n",
    "\n",
    "\n",
    "    # Calculate the EWMA of the training set using pandas\n",
    "    ewma_train_volatility = pd.DataFrame.ewm(pd.Series(train_volatility), span=span).mean()\n",
    "\n",
    "    # Initialize list for predicted volatilities\n",
    "    predicted_volatility = []\n",
    "\n",
    "    # Loop through the test set\n",
    "    for i in range(len(test_volatility)):\n",
    "        # Add current test point to training data\n",
    "        train_volatility = np.append(train_volatility, test_volatility[i])\n",
    "        # Update EWMA with new point\n",
    "        ewma_train_volatility = pd.DataFrame.ewm(pd.Series(train_volatility), span=span).mean()\n",
    "        # Get the last value of the EWMA as the forecasted volatility\n",
    "        forecasted_volatility = ewma_train_volatility.values[-1]\n",
    "        # Append forecasted value to list of predicted volatilities\n",
    "        predicted_volatility.append(forecasted_volatility)\n",
    "\n",
    "    pd.DataFrame(test_volatility,predicted_volatility)\n",
    "\n",
    "    return predicted_volatility\n",
    "\n",
    "\n",
    "def show_plot(test_volatility, predicted_volatility):\n",
    "    # Plot predicted values vs actual test values\n",
    "    plt.plot(range(len(test_volatility)), test_volatility, label='Actual Volatility')\n",
    "    plt.plot(range(len(predicted_volatility)), predicted_volatility, label='Predicted Volatility')\n",
    "    plt.legend()\n",
    "    plt.title('Actual vs Predicted Volatility')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Volatility')\n",
    "    plt.show()\n",
    "\n",
    "    # Calculate mean squared error (MSE)\n",
    "    mse = np.mean((predicted_volatility - test_volatility)**2)\n",
    "    print(\"Mean Squared Error (MSE):\", mse)\n",
    "\n",
    "    # Calculate root mean squared error (RMSE)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(\"Root Mean Squared Error (RMSE):\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EWMA_each_stock(df,span=3):\n",
    "\n",
    "    # Read the CSV file into a pandas DataFrame\n",
    "    stock = pd.read_csv(stock)\n",
    "\n",
    "    # Get a list of unique time ids\n",
    "    time_ids = stock['time_id'].unique()\n",
    "\n",
    "    # Loop through the unique time ids\n",
    "    ls = []\n",
    "    first = True\n",
    "    for time_id in time_ids:\n",
    "        \n",
    "        time_id_rows = stock[stock['time_id'] == time_id]\n",
    "        ls.append(ewma_mse(df[\"volatility\"],span))\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\"time_id\":[1, 1, 2, 2],\n",
    "                    \"volatility\":[5, 6, 7, 8]})\n",
    "  \n",
    "EWMA_each_stock(df,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   time_id  seconds  volatility  predicted\n",
      "8        1        9          13  12.017613\n",
      "9        1       10          14  13.009775\n",
      "    time_id  seconds  volatility  predicted\n",
      "8         1        9          13  12.017613\n",
      "9         1       10          14  13.009775\n",
      "16        2       17          21  20.055118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cecil\\AppData\\Local\\Temp\\ipykernel_12856\\1767191143.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ans[\"predicted\"] = predicted_volatility\n",
      "C:\\Users\\cecil\\AppData\\Local\\Temp\\ipykernel_12856\\1767191143.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ans[\"predicted\"] = predicted_volatility\n",
      "C:\\Users\\cecil\\AppData\\Local\\Temp\\ipykernel_12856\\1767191143.py:45: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ans = ans.append(ewma_predict(time_id_rows,span))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_id</th>\n",
       "      <th>seconds</th>\n",
       "      <th>volatility</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>12.017613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>13.009775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>20.055118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    time_id  seconds  volatility  predicted\n",
       "8         1        9          13  12.017613\n",
       "9         1       10          14  13.009775\n",
       "16        2       17          21  20.055118"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ewma_predict(df, span):\n",
    "    # Split the data into training and testing sets\n",
    "\n",
    "    volatility = list(df[\"volatility\"])\n",
    "    ans = df.tail(round(len(volatility)*0.2))\n",
    "\n",
    "    train_volatility = volatility[:round(len(volatility)*0.8)]\n",
    "    test_volatility = volatility[round(len(volatility)*0.8):]\n",
    "    # Calculate the EWMA of the training set using pandas\n",
    "    ewma_train_volatility = pd.DataFrame.ewm(pd.Series(train_volatility), span=span).mean()\n",
    "\n",
    "    # Initialize list for predicted volatilities\n",
    "    predicted_volatility = []\n",
    "\n",
    "    # Loop through the test set\n",
    "    for i in range(len(test_volatility)):\n",
    "        \n",
    "        # Add current test point to training data\n",
    "        train_volatility = np.append(train_volatility, test_volatility[i])\n",
    "        # Update EWMA with new point\n",
    "        ewma_train_volatility = pd.DataFrame.ewm(pd.Series(train_volatility), span=span).mean()\n",
    "        # Get the last value of the EWMA as the forecasted volatility\n",
    "        forecasted_volatility = ewma_train_volatility.values[-1]\n",
    "        # Append forecasted value to list of predicted volatilities\n",
    "        predicted_volatility.append(forecasted_volatility)\n",
    "    \n",
    "    ans[\"predicted\"] = predicted_volatility\n",
    "    return ans\n",
    "\n",
    "\n",
    "def EWMA_each_stock(stock,span=3):\n",
    "    # Get a list of unique time ids\n",
    "    time_ids = stock['time_id'].unique()\n",
    "    # Loop through the unique time ids\n",
    "    first = True\n",
    "    for time_id in time_ids:\n",
    "\n",
    "        time_id_rows = stock[stock['time_id'] == time_id]\n",
    "\n",
    "        if first == True:\n",
    "            ans = ewma_predict(time_id_rows,span)\n",
    "            print(ans)\n",
    "            first = False\n",
    "        else:\n",
    "            ans = ans.append(ewma_predict(time_id_rows,span))\n",
    "            print(ans)\n",
    "\n",
    "    return ans\n",
    "\n",
    "df = pd.DataFrame({\"time_id\":[1, 1, 1,1, 1, 1,1,1,1,1,2,2,2,2,2,2,2],\n",
    "                   \"seconds\":[1, 2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17],\n",
    "                    \"volatility\":[5, 6, 7, 8,9,10,11,12,13,14,15,16,17,18,19,20,21]})\n",
    "\n",
    "\n",
    "\n",
    "EWMA_each_stock(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
